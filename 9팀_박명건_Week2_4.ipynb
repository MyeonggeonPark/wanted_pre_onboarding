{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "592U6lXs3d2t"
      },
      "source": [
        "# Week2_4 Assignment\n",
        "\n",
        "## [BASIC](#Basic) \n",
        "- 커스텀 모듈(`helper.py`)에서 **클래스와 함수를 임포트**할 수 있다.\n",
        "- **autograd**의 개념 복습\n",
        "\n",
        "\n",
        "## [CHALLENGE](#Challenge)\n",
        "- train() 함수에 **epoch, scheduler, grad_clipping**을 추가할 수 있다.\n",
        "- **validate() 함수를 구현**할 수 있다.\n",
        "\n",
        "\n",
        "## [ADVANCED](#Advanced)\n",
        "- train() 함수를 사용해 데이터를 **4 epoch 학습**할 수 있다. \n",
        "- **predict 함수를 구현**할 수 있다. \n",
        "- **evaluation metric 구현**할 수 있다. \n",
        "    - accuracy\n",
        "\n",
        "\n",
        "\n",
        "### Reference\n",
        "- [Pytorch Autograd Explain official document](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:47.370876Z",
          "start_time": "2022-02-02T04:01:46.520392Z"
        },
        "id": "KSX-wQA1RD1h"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import torch\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:47.375658Z",
          "start_time": "2022-02-02T04:01:47.372242Z"
        },
        "id": "MH7RJjtZXOHf"
      },
      "outputs": [],
      "source": [
        "# set seed\n",
        "seed = 7777\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-31T13:07:00.849353Z",
          "start_time": "2022-01-31T13:06:56.187962Z"
        },
        "id": "62plMahMWr0U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fb890be-c996-481c-a086-61ec19fba680"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.16.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6WagJcj-Ud4L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e93a065-2de9-4b57-c99d-09f68f4e09c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7s72r8woAr-",
        "outputId": "56eeb67d-1060-4f16-e6b4-ad4236e3205d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/Classroom/AI심화과정\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7eOua96oD01",
        "outputId": "188f6999-7873-462c-f0a7-8b4ae6af74e6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Classroom/AI심화과정\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmpsFKrjoPw1",
        "outputId": "725c7c9b-ddcd-4cfe-916a-c82cb05454cd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'9팀_박명건(Day2).ipynb'   sample_df_test.csv\n",
            "'9팀_박명건(Day3).ipynb'   sample_df_test.csv.1\n",
            " 9팀_박명건.docx\t   sample_df_test.csv.2\n",
            " model.ckpt.0\t\t   sample_df_test.csv.3\n",
            " model.ckpt.1\t\t   sample_df_test.csv.4\n",
            " model.ckpt.2\t\t  '박명건 - Week1-4 과제.gdoc'\n",
            " model.ckpt.3\t\t   Week1_Day1.pdf\n",
            " models\t\t\t   Week1_Day2.pdf\n",
            " nsmc\t\t\t   Week1_Day3.pdf\n",
            " pretest_data.csv\t  '박명건 - Week2_1_assignment.ipynb'\n",
            " sample_df.csv\t\t  '박명건 - Week2_2_assignment.ipynb'\n",
            " sample_df.csv.1\t  '박명건 - Week2_3_assignment (1).ipynb'\n",
            " sample_df.csv.2\t  '박명건 - Week2_3_assignment.ipynb'\n",
            " sample_df.csv.3\t  '박명건 - Week2_4_assignment.ipynb'\n",
            " sample_df.csv.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from models import helper"
      ],
      "metadata": {
        "id": "K8WSmiuzombY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "qnETqIqdVApF"
      },
      "outputs": [],
      "source": [
        "# 어제 자신이 구현한 helper.py 모듈 경로를 입력\n",
        "sys.path.append('/content/drive/MyDrive/Classroom/AI심화과정')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.path.abspath(os.curdir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpWjnpOjj_KM",
        "outputId": "9b37ec9a-296c-4f09-ba2d-cdbcb2f9be47"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Classroom/AI심화과정\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:49.735578Z",
          "start_time": "2022-02-02T04:01:49.475969Z"
        },
        "id": "N84mZeYMUFxJ"
      },
      "outputs": [],
      "source": [
        "# helper 모듈을 import하면 이전에 구현했던 다양한 함수 및 클래스를 사용할 수 있음 \n",
        "# 함수: set_device()\n",
        "# 함수: custom_collate_fn() \n",
        "# 클래스: CustomDataset\n",
        "# 클래스: CustomClassifier\n",
        "# 가 import 됨\n",
        "\n",
        "from torch.utils.data import RandomSampler, SequentialSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:49.771743Z",
          "start_time": "2022-02-02T04:01:49.736866Z"
        },
        "id": "oR5EWmh5UFxK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b844612-c83d-4d80-c1cc-3d1b9f7f2587"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n"
          ]
        }
      ],
      "source": [
        "# device\n",
        "device = helper.set_device()\n",
        "print(f\"device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkNxrCV45Q3m"
      },
      "source": [
        "## Basic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YBUQykS5Q3n"
      },
      "source": [
        "### 모듈에서 클래스와 함수를 임포트해 다음을 구현\n",
        "- train_dataset, train_dataloader\n",
        "- valid_dataset, valid_dataloader\n",
        "- test_dataset, test_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train dataframe 다운로드\n",
        "!wget https://raw.githubusercontent.com/ChristinaROK/PreOnboarding_AI_assets/e56006adfac42f8a2975db0ebbe60eacbe1c6b11/data/sample_df.csv"
      ],
      "metadata": {
        "id": "cjNksUEwGACb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3801e1ab-0379-4629-c025-e584c887cbb9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-03 09:47:32--  https://raw.githubusercontent.com/ChristinaROK/PreOnboarding_AI_assets/e56006adfac42f8a2975db0ebbe60eacbe1c6b11/data/sample_df.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 971625 (949K) [text/plain]\n",
            "Saving to: ‘sample_df.csv.5’\n",
            "\n",
            "sample_df.csv.5     100%[===================>] 948.85K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2022-03-03 09:47:32 (22.4 MB/s) - ‘sample_df.csv.5’ saved [971625/971625]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test dataframe 다운로드\n",
        "!wget https://raw.githubusercontent.com/ChristinaROK/PreOnboarding_AI_assets/main/data/sample_df_test.csv"
      ],
      "metadata": {
        "id": "kXfk8ZEHGB0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d44af335-2390-4447-fe52-353d988b915e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-03 09:47:33--  https://raw.githubusercontent.com/ChristinaROK/PreOnboarding_AI_assets/main/data/sample_df_test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 101383 (99K) [text/plain]\n",
            "Saving to: ‘sample_df_test.csv.5’\n",
            "\n",
            "\rsample_df_test.csv.   0%[                    ]       0  --.-KB/s               \rsample_df_test.csv. 100%[===================>]  99.01K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2022-03-03 09:47:33 (9.31 MB/s) - ‘sample_df_test.csv.5’ saved [101383/101383]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:53.037044Z",
          "start_time": "2022-02-02T04:01:52.707669Z"
        },
        "id": "KVo5dPnmUFxK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a04e4c7-ed09-43f6-8fe0-7eb1677c9206"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train shape : (10000, 3)\n",
            "test shape : (1000, 3)\n"
          ]
        }
      ],
      "source": [
        "# 학습 & 평가 데이터셋 로드\n",
        "# 학습 및 평가 샘플 데이터 개수는 각각 10,000개, 1,000개\n",
        "\n",
        "df_train = pd.read_csv('sample_df.csv')\n",
        "df_test = pd.read_csv('sample_df_test.csv')\n",
        "\n",
        "print(f\"train shape : {df_train.shape}\")\n",
        "print(f\"test shape : {df_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "lRK20nWMqZ78",
        "outputId": "5dac8ef8-2c08-47ad-b631-a52fa9ccc05f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cd617f0c-1952-4e09-957e-d345e494508f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8525343</td>\n",
              "      <td>나 이거 더빙을 누가하는지 모르고 봤는데 왠지 더빙이 구리더라...더빙이 너무 별로였음.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4572888</td>\n",
              "      <td>현암이 소지섭이었으면 좋았겠는데..스토리각색도 좀 깔끔하게...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8504845</td>\n",
              "      <td>ㅎㅎㅎ 대단하네 ㅜ,.ㅡ</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5003367</td>\n",
              "      <td>이거보고 돈날린 기억이...........</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3015049</td>\n",
              "      <td>한국영화 어쩌다 이지경까지 ㅠㅠ</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd617f0c-1952-4e09-957e-d345e494508f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cd617f0c-1952-4e09-957e-d345e494508f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cd617f0c-1952-4e09-957e-d345e494508f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        id                                           document  label\n",
              "0  8525343  나 이거 더빙을 누가하는지 모르고 봤는데 왠지 더빙이 구리더라...더빙이 너무 별로였음.      0\n",
              "1  4572888                현암이 소지섭이었으면 좋았겠는데..스토리각색도 좀 깔끔하게...      0\n",
              "2  8504845                                      ㅎㅎㅎ 대단하네 ㅜ,.ㅡ      0\n",
              "3  5003367                            이거보고 돈날린 기억이...........      0\n",
              "4  3015049                                  한국영화 어쩌다 이지경까지 ㅠㅠ      0"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:53.085720Z",
          "start_time": "2022-02-02T04:01:53.081413Z"
        },
        "id": "Ql82Ew2VUFxM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97777148-4415-41e0-a311-105bc6bc0812"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset len: 10000\n",
            "Train Dataset 1st element: ('나 이거 더빙을 누가하는지 모르고 봤는데 왠지 더빙이 구리더라...더빙이 너무 별로였음.', 0)\n",
            "Test Dataset len: 1000\n",
            "Test Dataset 1st element: ('신용문객잔 보고 후속편인줄 알고 봤더만 완전 개판이네 18.. 이련결 그냥 절에나 쳐 들어 가라.. 회오리에서 싸우는 신 참 가관이더라 .. 서극도 완전 쓰레기 감독이 다 됐구나.. 액션도 쓰레기고 배우들 연기도 참 가관이더라 18', 0)\n"
          ]
        }
      ],
      "source": [
        "# Dataset 구현\n",
        "# helper.py에 있는 CustomDataset 활용하여 train datset, test dataset 만들기\n",
        "\n",
        "train_dataset = helper.CustomDataset(df_train.document, df_train.label)\n",
        "test_dataset = helper.CustomDataset(df_test.document, df_test.label)\n",
        "\n",
        "print(f\"Train Dataset len: {len(train_dataset)}\")\n",
        "print(f\"Train Dataset 1st element: {train_dataset[0]}\")\n",
        "\n",
        "print(f\"Test Dataset len: {len(test_dataset)}\")\n",
        "print(f\"Test Dataset 1st element: {test_dataset[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "0cSwuz5EoqaV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:53.152070Z",
          "start_time": "2022-02-02T04:01:53.145410Z"
        },
        "id": "7WUY6h8WUFxM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1841b852-059e-4ea8-863d-f665f45c5670"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset len: 9000\n",
            "Valid dataset len: 1000\n"
          ]
        }
      ],
      "source": [
        "# Train Dataset을 학습과 검증 셋으로 분리\n",
        "# 학습 셋과 검증 셋의 비율은 9:1\n",
        "# torch.utils.data에서 제공되는 데이터 세트를 임의로 분할할 수 있는 함수 찾아서 사용\n",
        "n_train_sample = df_train.shape[0]\n",
        "\n",
        "n_train = int(n_train_sample*0.9)\n",
        "n_valid = n_train_sample - n_train \n",
        "train_dataset, valid_dataset = random_split(train_dataset, [n_train, n_valid], generator=torch.Generator().manual_seed(seed))\n",
        "\n",
        "print(f\"Train dataset len: {len(train_dataset)}\")\n",
        "print(f\"Valid dataset len: {len(valid_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:53.268838Z",
          "start_time": "2022-02-02T04:01:53.263780Z"
        },
        "id": "H5nc7SpTUFxM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66e016b5-177a-4715-d5bb-9015718c6e61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataloader # steps: 282\n",
            "Valid dataloader # steps: 16\n",
            "Test dataloader # steps: 16\n"
          ]
        }
      ],
      "source": [
        "# DataLoader 구현\n",
        "# train과 validation의 batch size는 각각 32, 64로 설정\n",
        "# test의 batch size는 validation과 동일\n",
        "# train에 사용할 DataLoader에서는 sampler로 RandomSampler 사용\n",
        "# validation과 test에 사용할 DataLoader에서는 sampler로 SequentialSampler 사용\n",
        "# 모든 DataLoader의 collate_fn은 helper.py에 있는 custom_collate_fn 사용\n",
        "\n",
        "train_batch_size = 32\n",
        "valid_batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = train_batch_size, collate_fn = helper.custom_collate_fn, sampler = RandomSampler(train_dataset, generator=torch.Generator().manual_seed(seed)))\n",
        "\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size = valid_batch_size, collate_fn = helper.custom_collate_fn, sampler = SequentialSampler(valid_dataset))\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = valid_batch_size, collate_fn = helper.custom_collate_fn, sampler = SequentialSampler(test_dataset))\n",
        "\n",
        "print(f\"Train dataloader # steps: {len(train_dataloader)}\")\n",
        "print(f\"Valid dataloader # steps: {len(valid_dataloader)}\")\n",
        "print(f\"Test dataloader # steps: {len(test_dataloader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kEgqvBIUFxN"
      },
      "source": [
        "### `auto_grad` 개념 복습\n",
        "- torch의 `auto_grad` 기능\n",
        "    - pytorch는 `requires_grad` 파리미터의 값이 True인 텐서에 한해서 미분값을 자동으로 계산한다.\n",
        "    - 미분값은 `loss.backward()` 가 호출될 때 자동으로 계산된다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-31T13:45:23.502936Z",
          "start_time": "2022-01-31T13:45:20.029987Z"
        },
        "id": "oYjYpQ1DUFxN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122,
          "referenced_widgets": [
            "8eaecfbde3fe40cf998554ec44b91279",
            "7e1053fcfaa44958a9fd9fd8971066bb",
            "ea9d603ae1884bf6a854d5fe1d259b07",
            "9ba1067ebd1349a39fbd1f351b575b67",
            "5da27b826a044dfa879622e056e71c83",
            "53b039f04e70415da34b5916b8373757",
            "c62f41c7d6154a8b99177b1abe46238b",
            "071c2f5dc4e24c10965e3726add3cdbf",
            "990f268312424aecaed6be37936424fe",
            "38462e8fc28945ad9c97e3c4ab07cdc5",
            "71464a793bf1476ca33e533cdc4c10b1"
          ]
        },
        "outputId": "70b39b19-5308-4573-a8b3-f0a554d123e4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8eaecfbde3fe40cf998554ec44b91279",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/424M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# helper.py에 있는 CustomClassifier 모델을 로드해 model_freeze 변수에 instance를 생성\n",
        "# hidden_size=768\n",
        "# n_label=2\n",
        "# freeze_base=True\n",
        "\n",
        "model_freeze = helper.CustomClassifier(hidden_size=768, n_label=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-31T13:45:34.604914Z",
          "start_time": "2022-01-31T13:45:34.586711Z"
        },
        "id": "XxNFh8KZUFxN"
      },
      "outputs": [],
      "source": [
        "# model_freeze 모델의 모든 파라미터를 출력해보고 아래 질문에 답해 보자\n",
        "\n",
        "None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_freeze.bert.encoder.layer[0].attention.self.query.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lef_1ovW3CQW",
        "outputId": "3f74f698-1998-4647-f9de-08ca6d52d5db"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.0136,  0.0162, -0.0616,  ..., -0.0227, -0.0551, -0.0385],\n",
              "        [ 0.0549, -0.0462, -0.0229,  ...,  0.0028, -0.0088,  0.0135],\n",
              "        [ 0.0275,  0.0846,  0.0093,  ..., -0.0018,  0.0184, -0.0297],\n",
              "        ...,\n",
              "        [ 0.0105, -0.0079, -0.0426,  ...,  0.0378, -0.0219,  0.0065],\n",
              "        [-0.0283,  0.0635,  0.0240,  ...,  0.0183,  0.0244, -0.0108],\n",
              "        [ 0.0601, -0.0081,  0.0419,  ...,  0.0085,  0.0259,  0.0199]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_freeze.classifier[0].weight.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVm2UBGs3eSM",
        "outputId": "87a7fd03-1d51-42fe-a2b8-28f84c9dd682"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_freeze.classifier[0].weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gSnGaMy51_x",
        "outputId": "5439bc80-a8d2-4cef-f98d-0bbe75ffc1d5"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0054, -0.0320, -0.0232,  ...,  0.0100,  0.0236, -0.0361],\n",
              "        [ 0.0304,  0.0071, -0.0329,  ..., -0.0179, -0.0109,  0.0322],\n",
              "        [-0.0081, -0.0125,  0.0354,  ...,  0.0185,  0.0277, -0.0293],\n",
              "        ...,\n",
              "        [ 0.0169,  0.0198,  0.0159,  ...,  0.0302, -0.0136,  0.0208],\n",
              "        [ 0.0278, -0.0230,  0.0042,  ..., -0.0138, -0.0280, -0.0031],\n",
              "        [ 0.0096, -0.0306, -0.0141,  ...,  0.0110, -0.0127,  0.0322]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(model_freeze.classifier[0].weight)"
      ],
      "metadata": {
        "id": "4VpjBNiW7VO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_freeze.classifier[0].weight.requires_grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e8aeV5o74h2",
        "outputId": "e01d4872-4283-4758-a40f-0692f78b8d2f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_freeze.classifier[0].weight.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgDufZwR74kp",
        "outputId": "6d753a42-69ec-4b0f-c205-5e24ef555e63"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KloNNAKI5Q3r"
      },
      "source": [
        "### `auto_grad` 개념 및 모델 구조 복습을 위해 다음 항목에 답해 보자\n",
        "- `bert.encoder.layer.0.attention.self.query.weight` 텐서의 gradient는 True인 상태인가?\n",
        "> requires_grad=True\n",
        "- `classifier.0.weight` 텐서의 shape은? \n",
        "> torch.Size([32, 768])\n",
        "- `classifier.0.weight` 텐서는 freeze 상태인가 ? \n",
        "> requires_grad=True\n",
        "- `classifier.0.weight` 텐서의 gradient 값은 무엇인가? \n",
        "> None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iIrHg1xUFxP"
      },
      "source": [
        "### 위 모델 (`model_freeze`)의 모든 파라미터의 gradient를 freeze 해보자"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-31T13:49:26.820569Z",
          "start_time": "2022-01-31T13:49:26.816511Z"
        },
        "id": "sHkaFgC8UFxP"
      },
      "outputs": [],
      "source": [
        "# 모든 파라미터의 gradient를 freeze 해보고 제대로 변경되었는지 \b확인하기 위해 모델의 모든 파라미터를 출력해보자.\n",
        "\n",
        "for param in model_freeze.bert.parameters():\n",
        "  param.requires_grad=False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsMgM3sK5Q3t"
      },
      "source": [
        "## Challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUn-6PFP5Q3t"
      },
      "source": [
        "### `scheduler` 를 생성 \n",
        "- 스케쥴러를 알기 전에 먼저 `epoch`의 개념을 알아야 한다. Epoch는 dataset를 **몇 번 반복**해 학습할 것인지를 의미한다. 만약 dataset의 개수가 2,000개이고 epoch을 2번 학습하게 되면 총 4,000개의 데이터를 학습하게 된다.   \n",
        "- 스케쥴러는 epoch에 따라 learning rate의 값을 조정하는 것을 의미한다. \n",
        "- 예를 들어 [여기](https://huggingface.co/docs/transformers/main_classes/optimizer_schedules#transformers.get_linear_schedule_with_warmup)의 그림에서 볼 수 있듯이 `get_linear_schedule_with_warmup`는 특정 step까지는 learning rate를 천천히 상승시키다가 고점에 도달하면 다시 하락시킨다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FuADvuT5Q3t"
      },
      "source": [
        "### `model`, `optimizer`, `scheduler`를 초기화(=인스턴스 생성)하는 함수를 구현하라"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:59.217735Z",
          "start_time": "2022-02-02T04:01:59.210482Z"
        },
        "id": "-sE7xjYcRD1p"
      },
      "outputs": [],
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import AdamW\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from transformers import get_linear_schedule_with_warmup, get_constant_schedule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:01:59.549660Z",
          "start_time": "2022-02-02T04:01:59.545752Z"
        },
        "id": "2eTFXzy8VK9R"
      },
      "outputs": [],
      "source": [
        "# model:CustomClassifier 사용, hidden size는 768, label 개수는 2\n",
        "# optimizer: AdamW 사용, learning rate는 2e-5\n",
        "# scheduler: transformers.get_linear_schedule_with_warmup 함수 사용, 단, num_warmup_steps 매개 변수는 사용하지 않음\n",
        "\n",
        "def initializer(train_dataloader, epochs=2):\n",
        "    \"\"\"\n",
        "    모델, 옵티마이저, 스케쥴러를 초기화한 후 반환\n",
        "    \"\"\"\n",
        "    \n",
        "    model = helper.CustomClassifier(hidden_size=768, n_label=2)\n",
        "\n",
        "    optimizer = AdamW(\n",
        "        model.parameters(),\n",
        "        lr=2e-5,\n",
        "        eps=1e-8\n",
        "        )\n",
        "    \n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    print(f\"Total train steps with {epochs} epochs: {total_steps}\")\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)\n",
        "\n",
        "    return model, optimizer, scheduler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z696JA9Obo35",
        "outputId": "97de0d62-9466-480e-d5cf-26238e13d5ce"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "282"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz-8_5as5Q3u"
      },
      "source": [
        "### model, optimizer, scheduler의 파라미터 저장하는 함수를 구현하라"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:02:02.786877Z",
          "start_time": "2022-02-02T04:02:02.783726Z"
        },
        "id": "vIP1BjFA5Q3u"
      },
      "outputs": [],
      "source": [
        "# 모델 저장 함수 구현\n",
        "\n",
        "def save_checkpoint(path, model, optimizer, scheduler, epoch, loss):\n",
        "    file_name = f'{path}/model.ckpt.{epoch}'\n",
        "    \n",
        "    # torch.save 함수 참고\n",
        "    torch.save(\n",
        "        {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'loss' : loss\n",
        "        }, \n",
        "        file_name\n",
        "    )\n",
        "    \n",
        "    print(f\"Saving epoch {epoch} checkpoint at {file_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(model_freeze)"
      ],
      "metadata": {
        "id": "b5NxLdkFJo4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3BUrgtJ5Q3v"
      },
      "source": [
        "### `validate()` 함수 구현 \n",
        "- `validate()` 함수 내 model의 상태는 **evaluate**이어야 한다. evaluate 상태의 model은 dropout을 진행하지 않는다. \n",
        "- **forward**를 진행할 때 `with torch.no_grad(): ...` 설정해 미분 계산을 방지한다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:02:11.636684Z",
          "start_time": "2022-02-02T04:02:11.631550Z"
        },
        "id": "VHpuV0CXUFxR"
      },
      "outputs": [],
      "source": [
        "# input: model, valid_dataloader\n",
        "# output: loss, 정확도\n",
        "\n",
        "def validate(model, valid_dataloader):\n",
        "  global loss_fct\n",
        "   \n",
        "    # 모델을 evaluate 모드로 설정 & device 할당\n",
        "  model.eval()\n",
        "  model.to(device)\n",
        "    \n",
        "  total_loss, total_acc= 0,0\n",
        "        \n",
        "  for step, batch in enumerate(valid_dataloader):\n",
        "        \n",
        "        # tensor 연산 전, 각 tensor에 device 할당\n",
        "        batch = tuple(item.to(device) for item in batch)\n",
        "            \n",
        "        batch_input, batch_label = batch\n",
        "            \n",
        "        # gradient 계산하지 않고 forward 진행\n",
        "        with torch.no_grad():\n",
        "            logits = model(**batch_input)\n",
        "            \n",
        "        # loss\n",
        "        loss = loss_fct(logits, batch_label)\n",
        "        total_loss += loss.item()\n",
        "        \n",
        "        # accuracy\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        preds = torch.argmax(probs, dim=1).flatten()\n",
        "        acc = (preds == batch_label).cpu().numpy().mean()\n",
        "        total_acc+=acc\n",
        "        \n",
        "  total_loss = total_loss/(step+1)\n",
        "  total_acc = total_acc/(step+1)*100\n",
        "\n",
        "  return total_loss, total_acc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NukaJc15UFxQ"
      },
      "source": [
        "### `train()` 함수에 `epoch`와 `clip_grad_norm` 추가\n",
        "- data_loader를 `epoch`만큼 반복하면서 학습하도록 `train()` 함수를 수정하라\n",
        "- `gradient cliping`은 미분 값 너무 큰 경우 gradient exploding되는 현상을 막기 위해 미분값이 `threshold`를 넘을 경우 특정 비율을 미분 값에 곱해 크기를 줄여준다.\n",
        "- Reference\n",
        "  - [clip_grad_norm_ official document](https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html)\n",
        "  - [그래디언트 클립핑 설명 한국어 블로그](https://kh-kim.gitbook.io/natural-language-processing-with-pytorch/00-cover-6/05-gradient-clipping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T04:02:10.624280Z",
          "start_time": "2022-02-02T04:02:10.615781Z"
        },
        "id": "ZvY5rxDKHQAp"
      },
      "outputs": [],
      "source": [
        "# 위에서 구현한 모델 저장 함수(save_checkpoint)와 validate 함수도 추가해보자\n",
        "\n",
        "loss_fct = CrossEntropyLoss()\n",
        "\n",
        "def train(model, train_dataloader, valid_dataloader=None, epochs=2):\n",
        "        global scheduler, loss_fct\n",
        "        \n",
        "        # train_dataloaer 학습을 epochs만큼 반복\n",
        "        for epoch in range(epochs):\n",
        "            print(f\"*****Epoch {epoch} Train Start*****\")\n",
        "            \n",
        "            # 배치 단위 평균 loss와 총 평균 loss 계산하기위해 변수 생성\n",
        "            total_loss, batch_loss, batch_count = 0,0,0\n",
        "        \n",
        "            # model을 train 모드로 설정 & device 할당\n",
        "            model.train()\n",
        "            model.to(device)\n",
        "            \n",
        "            # data iterator를 돌면서 하나씩 학습\n",
        "            for step, batch in enumerate(train_dataloader):\n",
        "                batch_count+=1\n",
        "                \n",
        "                # tensor 연산 전, 각 tensor에 device 할당\n",
        "                batch = tuple(item.to(device) for item in batch)\n",
        "            \n",
        "                batch_input, batch_label = batch\n",
        "            \n",
        "                # batch마다 모델이 갖고 있는 기존 gradient를 초기화\n",
        "                model.zero_grad()\n",
        "            \n",
        "                # forward\n",
        "                logits = model(**batch_input)\n",
        "            \n",
        "                # loss\n",
        "                loss = loss_fct(logits, batch_label)\n",
        "                batch_loss += loss.item()\n",
        "                total_loss += loss.item()\n",
        "            \n",
        "                # backward -> 파라미터의 미분(gradient)를 자동으로 계산\n",
        "                loss.backward()\n",
        "                \n",
        "                # gradient clipping 적용 (max_norm = 1)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = 1)\n",
        "          \n",
        "                # optimizer & scheduler 업데이트\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "                \n",
        "                # 배치 10개씩 처리할 때마다 평균 loss와 lr를 출력\n",
        "                if (step % 10 == 0 and step != 0):\n",
        "                    learning_rate = optimizer.param_groups[0]['lr']\n",
        "                    print(f\"Epoch: {epoch}, Step : {step}, LR : {learning_rate}, Avg Loss : {batch_loss / batch_count:.4f}\")\n",
        "\n",
        "                    # reset \n",
        "                    batch_loss, batch_count = 0,0\n",
        "\n",
        "            print(f\"Epoch {epoch} Total Mean Loss : {total_loss/(step+1):.4f}\")\n",
        "            print(f\"*****Epoch {epoch} Train Finish*****\\n\")\n",
        "            \n",
        "            if valid_dataloader is not None:\n",
        "                print(f\"*****Epoch {epoch} Valid Start*****\")\n",
        "                valid_loss, valid_acc = validate(model, valid_dataloader)\n",
        "                print(f\"Epoch {epoch} Valid Loss : {valid_loss:.4f} Valid Acc : {valid_acc:.2f}\")\n",
        "                print(f\"*****Epoch {epoch} Valid Finish*****\\n\")\n",
        "            \n",
        "            # checkpoint 저장\n",
        "            save_checkpoint(os.path.abspath(os.curdir), model, optimizer, scheduler, epoch, loss)\n",
        "                \n",
        "        print(\"Train Completed. End Program.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NWKzxIaf1QJ"
      },
      "source": [
        "## Advanced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFWnii7a5Q3w"
      },
      "source": [
        "### 학습 데이터를 epoch 4까지 학습\n",
        "- 매 epoch마다 다음을 수행한다.\n",
        "  - 학습이 끝난 후 validate() 함수 실행 \n",
        "  - validate() 함수가 끝난 후 model save 함수 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:02:11.377612Z",
          "start_time": "2022-02-02T04:02:20.931961Z"
        },
        "id": "7Er1qKtsf1QJ"
      },
      "outputs": [],
      "source": [
        "# 4 epoch 학습\n",
        "epochs=4\n",
        "model, optimizer, scheduler = initializer(train_dataloader, epochs)\n",
        "train(model, train_dataloader, valid_dataloader, epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T03:27:18.246441Z",
          "start_time": "2022-02-02T03:27:18.236617Z"
        },
        "id": "vA3_vqqCXccc"
      },
      "source": [
        "### 가장 dev acc 성능이 높았던 epoch의 모델의 체크 포인트를 불러와 로드하자"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:22:27.646150Z",
          "start_time": "2022-02-02T06:22:26.945572Z"
        },
        "id": "mvfkSff25Q3z"
      },
      "outputs": [],
      "source": [
        "# torch.load 함수 사용\n",
        "\n",
        "checkpoint = torch.load('/content/drive/MyDrive/Classroom/AI심화과정/model.ckpt.3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:22:36.415665Z",
          "start_time": "2022-02-02T06:22:36.407250Z"
        },
        "id": "YqcxMmTj5Q3z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a516da6-7163-402f-997f-20e395ee429c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'scheduler_state_dict', 'loss'])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# checkpoint의 key 종류를 확인\n",
        "checkpoint.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:22:40.272939Z",
          "start_time": "2022-02-02T06:22:37.010491Z"
        },
        "id": "wTvFYgNi5Q30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fa43ab5-a73b-4ea1-af53-17af42fc5d2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total train steps with 1 epochs: 282\n"
          ]
        }
      ],
      "source": [
        "# 위에서 구현한 initializer 함수 사용하여 model, optimizer, scheduler 초기화\n",
        "\n",
        "epochs=1\n",
        "model, optimizer, scheduler = initializer(train_dataloader, epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:22:40.443912Z",
          "start_time": "2022-02-02T06:22:40.274323Z"
        },
        "id": "CtR2sTW55Q30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "729d8c27-759a-43ff-ba1b-cbfcafadd119"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "model.load_state_dict(checkpoint[\"model_state_dict\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tzske7SR5Q30"
      },
      "source": [
        "### 모델 예측 함수 구현\n",
        "- test_dataloader를 입력받아 모델이 예측한 확률값 (probs)과 실제 정답 (label) 을 출력하는 `\bpredict()` 함수를 구현하자.\n",
        "- 함수 정의\n",
        "  - 입력 매개변수\n",
        "    - `model` : `CustomClassifier` 모델. logits를 반환함 \n",
        "    - `test_dataloader` : test 데이터셋의 텍스트와 레이블을 배치로 갖는 dataloader\n",
        "  - 조건\n",
        "    - `test_dataloader`는 이터레이터기 때문에 이터레이터를 순회하면서 `all_logits` 리스트에 배치 단위의 logits를 저장하고 `all_labels` 리스트에 배치 단위의 레이블 (0 또는 1 값)을 저장하라\n",
        "  - 반환값\n",
        "    - `probs`\n",
        "      - logits에 softmax 함수를 취한 확률값. (test data 개수, label 개수) shape을 가짐. \bnp.array 타입으로 데이터 타입을 변환할 것.\n",
        "    - `labels`\n",
        "      - 0 또는 1 값을 갖는 np.array. (test data 개수,) shape을 가짐."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:22:48.062229Z",
          "start_time": "2022-02-02T06:22:48.057531Z"
        },
        "id": "yQ7WiD1Oigg9"
      },
      "outputs": [],
      "source": [
        "def predict(model, test_dataloader):\n",
        "    \"\"\"\n",
        "    test_dataloader의 label별 확률값과 실제 label 값을 반환\n",
        "    \"\"\"\n",
        "\n",
        "    # model을 eval 모드로 설정 & device 할당\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    all_logits = []\n",
        "    all_labels = []\n",
        "\n",
        "    for step, batch in enumerate(test_dataloader):\n",
        "        batch = tuple(item.to(device) for item in batch)\n",
        "        batch_input, batch_label = batch\n",
        "        \n",
        "        # batch_input을 device 할당\n",
        "        batch_input.to(device)\n",
        "\n",
        "        # model에 batch_input을 넣어 logit 반환 & all_logits, all_labels 리스트에 값 추가 \n",
        "        with torch.no_grad():\n",
        "          logits = model(**batch_input)\n",
        "\n",
        "        all_logits.append(F.softmax(logits, dim=1))\n",
        "        all_labels.append(batch_label)\n",
        "\n",
        "    probs =  all_logits# logits을 확률값으로 변환 & Tensor 타입을 numpy.array 타입으로 변환\n",
        "    #all_labels #  Tensor 타입을 numpy.array 타입으로 변환\n",
        "\n",
        "    return probs, all_labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "        \n",
        "        # accuracy\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        preds = torch.argmax(probs, dim=1).flatten()\n",
        "        acc = (preds == batch_label).cpu().numpy().mean()\n",
        "        total_acc+=acc\n",
        "        \n",
        "  total_loss = total_loss/(step+1)\n",
        "  total_acc = total_acc/(step+1)*100\n",
        "\n",
        "  return total_loss, total_acc"
      ],
      "metadata": {
        "id": "gPF5-S-EWcNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델이 예측한 확률값과 실제 label을 입력 받아 정확도를 출력하는 **accuracy()** 함수를 구현하자. \n",
        "- 함수 정의 \n",
        "  - 입력 매개변수 \n",
        "    - `probs` : `predict()` 함수의 반환값. 2차원의 np.array\n",
        "    - `labels` : `predict()` 함수의 반환값. 1차원의 np.array\n",
        "  - 조건\n",
        "    - `probs`의 확률값이 0.5 이상이면 1, 이하이면 0이 되도록 만든다. 모델이 예측한 레이블을 실제값(`labels`)과 비교해 예측값과 실제값이 같으면 1, 다르면 0 점수를 준다. 모든 데이터에 대해 점수의 평균값이 accuracy 값이다. \n",
        "  - 반환값 \n",
        "    - `acc` : 정확도 (Float type)"
      ],
      "metadata": {
        "id": "lOxCjZ2g6ZeK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:22:48.296419Z",
          "start_time": "2022-02-02T06:22:48.293737Z"
        },
        "id": "42-umZ3m5Q32"
      },
      "outputs": [],
      "source": [
        "# accuracy 함수 구현\n",
        "def accuracy(probs, labels):\n",
        "  true_labels, total_len = [], []\n",
        "  [true_labels.append(np.count_nonzero((torch.argmax(probs[idx], dim=1).flatten() == labels[idx]).cpu().numpy())) for idx, _ in enumerate(probs)]\n",
        "  [total_len.append(len(label)) for label in labels]\n",
        "  return sum(true_labels) / sum(total_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:24:22.752497Z",
          "start_time": "2022-02-02T06:22:48.652784Z"
        },
        "id": "SwkrRPAhjsXb"
      },
      "outputs": [],
      "source": [
        "probs, labels = predict(model, test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:24:22.759367Z",
          "start_time": "2022-02-02T06:24:22.753997Z"
        },
        "id": "MxDI8PRA5Q32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9afe9c9-64b6-4783-f3bb-5880e3afd039"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.864"
            ]
          },
          "metadata": {},
          "execution_count": 256
        }
      ],
      "source": [
        "accuracy(probs, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mqUfkx-5Q33"
      },
      "source": [
        "### `sklearn.metrics`의 `accuracy_score`, `roc_auc_score` 함수를 이용해 정확도와 auc를 계산하라"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:24:23.111879Z",
          "start_time": "2022-02-02T06:24:22.760568Z"
        },
        "id": "VFWj4lcp5Q33"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:24:23.116872Z",
          "start_time": "2022-02-02T06:24:23.113064Z"
        },
        "id": "p9BEe2mflTem",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ed843dc-5c94-4a7a-c05e-e84a47e54560"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.864"
            ]
          },
          "metadata": {},
          "execution_count": 266
        }
      ],
      "source": [
        "# 정확도 출력\n",
        "probs_list = []\n",
        "for prob in probs:\n",
        "  probs_list.extend(torch.argmax(prob, dim=1).flatten().cpu().numpy())\n",
        "\n",
        "labels_list = []\n",
        "for label in labels:\n",
        "  labels_list.extend(label.cpu().numpy())\n",
        "\n",
        "accuracy_score(labels_list, probs_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-02-02T06:24:23.125650Z",
          "start_time": "2022-02-02T06:24:23.117847Z"
        },
        "id": "oCl6BiPGpCPW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfdb9be5-94f4-4bcd-8f87-a53c6f5c9a93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8639999999999999"
            ]
          },
          "metadata": {},
          "execution_count": 267
        }
      ],
      "source": [
        "# auc 출력\n",
        "\n",
        "roc_auc_score(labels_list, probs_list)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "9팀_박명건(Day4).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "torch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8eaecfbde3fe40cf998554ec44b91279": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7e1053fcfaa44958a9fd9fd8971066bb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ea9d603ae1884bf6a854d5fe1d259b07",
              "IPY_MODEL_9ba1067ebd1349a39fbd1f351b575b67",
              "IPY_MODEL_5da27b826a044dfa879622e056e71c83"
            ]
          }
        },
        "7e1053fcfaa44958a9fd9fd8971066bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ea9d603ae1884bf6a854d5fe1d259b07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_53b039f04e70415da34b5916b8373757",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c62f41c7d6154a8b99177b1abe46238b"
          }
        },
        "9ba1067ebd1349a39fbd1f351b575b67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_071c2f5dc4e24c10965e3726add3cdbf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 445025130,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 445025130,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_990f268312424aecaed6be37936424fe"
          }
        },
        "5da27b826a044dfa879622e056e71c83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_38462e8fc28945ad9c97e3c4ab07cdc5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 424M/424M [00:07&lt;00:00, 56.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_71464a793bf1476ca33e533cdc4c10b1"
          }
        },
        "53b039f04e70415da34b5916b8373757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c62f41c7d6154a8b99177b1abe46238b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "071c2f5dc4e24c10965e3726add3cdbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "990f268312424aecaed6be37936424fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "38462e8fc28945ad9c97e3c4ab07cdc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "71464a793bf1476ca33e533cdc4c10b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}